{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_CONFIG = {\n",
    "    'intents': {\n",
    "        'hello': {\n",
    "            'examples': ['Hello', 'Good day', 'Hey', 'Wazzap', 'Yo'],\n",
    "            'responses': ['Hello', \"Welcome\"]\n",
    "                },\n",
    "        'brands': {\n",
    "            'examples': ['Brands', 'Can you shaw me available vehicle brands, please?', 'available vehicle brands'],\n",
    "            'responses': ['Tesla, Nissan, NIO', 'Tesla, NIO, Nissan']\n",
    "                },\n",
    "        'cruise_range': {\n",
    "            'examples': ['range', 'cruise range', 'Can you show me cars with the maximum cruising range'],\n",
    "            'responses': ['Sure. That is Tesla Model S (640 km), NIO ec6 (615 km), NIO es6 (610 km)', 'Tesla Model S (640 km), NIO ec6 (615 km), NIO es6 (610 km)']\n",
    "                },\n",
    "        \n",
    "        'bye': {\n",
    "            'examples': ['Bye', 'Have a nice day', 'Good bye'], \n",
    "            'responses': ['If you need me  I will be here', 'See you', 'Bye', 'Have a nice day', 'Good bye' ]\n",
    "        }\n",
    "    },\n",
    "        \n",
    "    'failure_phrases': [\n",
    "        'Please write it in another way',\n",
    "        'Something is wrong',\n",
    "        'I do not understand. Repfrase your request, please',\n",
    "        'The list of my answers is limited. Ask the question in another way'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_texts = []\n",
    "y = []\n",
    "\n",
    "\n",
    "\n",
    "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
    "    for example in intent_data['examples']:\n",
    "        X_texts.append(example)\n",
    "        y.append(intent)\n",
    "            \n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "# vectorizer = TfidfVectorizer(analyzer='char_wb')\n",
    "# vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X_texts)\n",
    "clf = LinearSVC().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(question):\n",
    "    question_vector = vectorizer.transform([question])\n",
    "    intent = clf.predict(question_vector)[0]\n",
    "    \n",
    "    examples = BOT_CONFIG['intents'][intent]['examples'] \n",
    "    for example in examples:\n",
    "        dist = nltk.edit_distance(question, example)\n",
    "        dist_percentage = dist / len(example)\n",
    "        if dist_percentage < 0.4:\n",
    "            return intent\n",
    "    \n",
    "    \n",
    "#     index = list(clf_proba.classes_).index(intent)\n",
    "#     proba = clf_proba.predict_proba(question_vector)[0][index]\n",
    "#     print(intent, proba)\n",
    "#     if proba > 0.2:\n",
    "#         return intent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_by_intent(intent):\n",
    "    if intent in BOT_CONFIG['intents']:\n",
    "        phrases = BOT_CONFIG['intents'][intent]['responses']\n",
    "        return random.choice (phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I need to request a wake-up call for tomorrow morning.'], ['What time do you want the call?'], ['', 'I need two calls, one at 7 and another at 7:15.'], ['We can certainly do that. Expect a call from us at 7:00, and then again at 7:15.'], ['', 'Actually, can I change the latter wake-up call to 7:30 am?'], ['I can certainly do that. Is there anything else?'], ['', \"I can't think of anything. If I do think of something, I'll be sure to call again.\"], ['Okay. Good night, sir.'], ['', 'I need a wake-up call tomorrow morning.'], ['Of course. When would you like the call?'], ['', 'Actually, I need two calls, one at 7 and the other at 7:15.'], [\"No problem. We'll give you both calls.\"], ['', 'This bus goes all the way to Santa Anita mall, right?'], [\"Yes, it'll take us there.\"], ['', 'Are you positive?'], ['I always catch this bus.'], ['', 'How long is this bus ride?'], ['It only takes half an hour.'], ['', 'Where do we get off at?'], [\"We can get off the bus right behind Macy's.\"]]\n"
     ]
    }
   ],
   "source": [
    "def filter_text(text):\n",
    "    text = text.lower()\n",
    "    text = [c for c in text if c in 'abcdefghijklmnopqrstuvwxyz- ']\n",
    "    text = ''.join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# fileObj = codecs.open( \"dia.txt\", \"r\", \"utf_8_sig\" )\n",
    "with open('dia.txt') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "dialogues = [dialogue_line.split('\\n') for dialogue_line in content.split('\\n\\n')]\n",
    "\n",
    "questions = set ()\n",
    "qa_dataset = []\n",
    "\n",
    "for replicas in dialogues:\n",
    "    if len(replicas) < 2:\n",
    "        continue\n",
    "        \n",
    "    question, answer = replicas[:2]\n",
    "    question = filter_text(question[2:])\n",
    "    answer = answer[2:]\n",
    "    \n",
    "    if question and question not in questions:\n",
    "        questions.add(question)\n",
    "        qa_dataset.append([question, answer])\n",
    "\n",
    "\n",
    "qa_by_word_dataset = {} # {'word': [[q, a], ...]}\n",
    "for question, answer in qa_dataset:\n",
    "    words = question.split(' ')\n",
    "    for word in words:\n",
    "        if word not in qa_by_word_dataset:\n",
    "            qa_by_word_dataset[word] = []\n",
    "        qa_by_word_dataset[word].append((question, answer))\n",
    "\n",
    "\n",
    "        \n",
    "qa_by_word_dataset_filtered = {word: qa_list\n",
    "                               for word, qa_list in qa_by_word_dataset.items()\n",
    "                               if len(qa_list) < 1000}\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer_by_text(text):\n",
    "    text = filter_text(text)\n",
    "    words = text.split(' ')\n",
    "    qa = []\n",
    "    for word in words:\n",
    "        if word in qa_by_word_dataset_filtered:\n",
    "            qa += qa_by_word_dataset_filtered[word]\n",
    "    qa = list(set(qa))[:1000]\n",
    "        \n",
    "    results =[]\n",
    "    for question, answer in qa:\n",
    "        dist = nltk.edit_distance(question, text)\n",
    "        dist_percentage = dist / len(question)\n",
    "        results.append([dist_percentage, question, answer])\n",
    "        \n",
    "    if results:\n",
    "        dist_percentage, question, answer = min(results, key=lambda pairs: pairs[0])\n",
    "        if dist_percentage < 0.2:\n",
    "            return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failure_phrase():\n",
    "    phrases = BOT_CONFIG ['failure_phrases']\n",
    "    return random.choice (phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot(question):\n",
    "    #NLU\n",
    "    intent = get_intent(question)\n",
    "    \n",
    "    #get answer\n",
    "    \n",
    "    #We are seaching ready answer\n",
    "    if intent:\n",
    "        answer = get_answer_by_intent(intent)\n",
    "        if answer:\n",
    "            stats[0] += 1\n",
    "            return answer\n",
    "        \n",
    "    #Generate eligible answer by text\n",
    "    answer = generate_answer_by_text(question)\n",
    "    if answer:\n",
    "        stats[1] += 1\n",
    "        return answer\n",
    "    \n",
    "    #zaglushka\n",
    "    stats[2] += 1\n",
    "    answer = get_failure_phrase()\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kjn\n",
      "Something is wrong [0, 0, 1]\n",
      "lkj\n",
      "The list of my answers is limited. Ask the question in another way [0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "question = None\n",
    "\n",
    "while question not in ['exit','finish']:\n",
    "    question = input()\n",
    "    answer = bot(question)\n",
    "    print (answer, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
